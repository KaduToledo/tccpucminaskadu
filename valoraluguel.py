# -*- coding: utf-8 -*-
"""valoraluguel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LwBBoJiN5-C7APQApo48R5L2dyjhZ-5F

MODELAGEM PREDITIVA DO VALOR DE ALUGUEIS DE APARTAMENTOS EM ALGUMAS CIDADES DO BRASIL
"""

!pip -q install yellowbrick

!pip -q install plotly --upgrade

import pandas as pd #carregamento de arquivos e manipulação csv
import numpy as np #metodos numéricos
import seaborn as sns #visualização de gráficos
import matplotlib.pyplot as plt #visualização de gráficos
import plotly.express as px #gráficos dinâmicos

!python --version

"""#**Base de dados das propriedades de São Paulo**

Retirado de: <https://www.kaggle.com/datasets/argonalyst/sao-paulo-real-estate-sale-rent-april-2019>

##Processamento e tratamento dos dados
"""

base_sp = pd.read_csv('/content/sao-paulo-properties-april-2019.csv')

base_sp

base_sp.info()

#Verificar se todos os tipos de dados são apartamentos
np.unique(base_sp['Property Type'], return_counts=True)

#Excluindo algumas colunas que não serão necessárias
base_sp.drop(["Latitude", "Longitude","Property Type","District","New","Swimming Pool","Elevator","Suites"], axis=1, inplace=True)

#Só trabalharemos com propriedades para locação.
base_sp[base_sp['Negotiation Type'] == 'sale']

#excluir linhas que possuem tipo de negociação venda
base_sp = base_sp.drop(base_sp[base_sp['Negotiation Type'] == 'sale'].index)

base_sp

np.unique(base_sp['Negotiation Type'], return_counts=True)

#Excluir a coluna que representa o tipo de negociação
base_sp.drop(["Negotiation Type"], axis=1, inplace=True)

#Somando o valor do condominio e o preço do aluguel, para termos o preço total
base_sp['Price'] = base_sp['Condo']+base_sp['Price']

#renomeando as colunas
base_sp = base_sp.rename(columns={"Price":"Preço"})
base_sp = base_sp.rename(columns={"Condo":"Condominio"})
base_sp = base_sp.rename(columns={"Size":"Tamanho"})
base_sp = base_sp.rename(columns={"Rooms":"Quartos"})
base_sp = base_sp.rename(columns={"Toilets":"Banheiros"})
base_sp = base_sp.rename(columns={"Parking":"Estacionamento"})
base_sp = base_sp.rename(columns={"Furnished":"Mobiliado"})

base_sp

#Colocando as colunas em ordem
base_sp = base_sp[['Tamanho', 'Quartos', 'Banheiros','Estacionamento','Mobiliado','Condominio','Preço']]

#Formatando a coluna preço e condomínio para float
base_sp[['Preço']] = base_sp[['Preço']].astype(float)
base_sp[['Condominio']] = base_sp[['Condominio']].astype(float)

base_sp.info()

#Verificar se existem outliers, algum dado inconsistente. 
grafico = px.scatter_matrix(base_sp, dimensions=['Tamanho', 'Condominio', 'Preço'])
grafico.show()

base_sp.loc[base_sp['Tamanho'] > 800]

#Vamos excluir alguns dados que possuem o maior tamanho, mas estão com preço do aluguel baixo
base_sp = base_sp.drop(base_sp[base_sp['Tamanho'] > 800].index)

grafico = px.scatter_matrix(base_sp, dimensions=['Quartos', 'Banheiros', 'Estacionamento', 'Mobiliado', 'Preço'])
grafico.show()

base_sp.loc[base_sp['Quartos'] == 10]

base_sp.loc[base_sp['Quartos'] == 6]

#Vamos excluir alguns dados que possuem um número grande de quartos, mas estão com preço baixo de aluguel
base_sp = base_sp.drop(base_sp[base_sp['Quartos'] == 10].index)
base_sp = base_sp.drop(base_sp[base_sp['Quartos'] == 6].index)

base_sp.loc[base_sp['Banheiros'] == 8]

#Vamos excluir um dado que possui um número grande de banheiro, mas esta com um preço baixo de aluguel
base_sp = base_sp.drop(base_sp[base_sp['Banheiros'] == 8].index)

base_sp.loc[base_sp['Estacionamento'] == 8]

base_sp.loc[base_sp['Estacionamento'] == 9]

#Vamos excluir alguns dados que possuem um número alto de estacionamentos, mas estão com preço baixo de aluguel
base_sp = base_sp.drop(base_sp[base_sp['Estacionamento'] == 8].index)
base_sp = base_sp.drop(base_sp[base_sp['Estacionamento'] == 9].index)

base_sp

"""#**Base de dados das propriedades de algumas cidades do Brasil**

Retirado de <https://www.kaggle.com/datasets/rubenssjr/brasilian-houses-to-rent>

##Processamento e tratamento dos dados
"""

base_fora = pd.read_csv('/content/houses_to_rent_v2.csv')

base_fora

base_fora.info()

#Verificar quais cidades estão incluidas na base de dados
np.unique(base_fora['city'], return_counts=True)

#Excluir algumas colunas que não serão necessárias
base_fora.drop(["city", "floor","animal","rent amount (R$)","property tax (R$)","fire insurance (R$)"], axis=1, inplace=True)

base_fora

#Renomeando as colunas
base_fora = base_fora.rename(columns={"total (R$)":"Preço"})
base_fora = base_fora.rename(columns={"hoa (R$)":"Condominio"})
base_fora = base_fora.rename(columns={"area":"Tamanho"})
base_fora = base_fora.rename(columns={"rooms":"Quartos"})
base_fora = base_fora.rename(columns={"bathroom":"Banheiros"})
base_fora = base_fora.rename(columns={"parking spaces":"Estacionamento"})
base_fora = base_fora.rename(columns={"furniture":"Mobiliado"})

#Fromatando algumas colunas
base_fora[['Preço']] = base_fora[['Preço']].astype(float)
base_fora[['Condominio']] = base_fora[['Condominio']].astype(float)

#Trocar não mobiliado por 0 e mobiliado por 1
base_fora['Mobiliado'] = base_fora['Mobiliado'].apply(lambda x: x.replace('not furnished', '0').replace('furnished', '1'))

base_fora

#Formatar a coluna mobiliado pro tipo inteiro
base_fora[['Mobiliado']] = base_fora[['Mobiliado']].astype(int)

base_fora.info()

#Visualizar algum dado inconsistente 
grafico = px.scatter_matrix(base_fora, dimensions=['Tamanho', 'Condominio', 'Preço'])
grafico.show()

base_fora.loc[base_fora['Tamanho'] > 1000]

#Excluir dados cujo tamanho em m^2 é maior que 1000
base_fora = base_fora.drop(base_fora[base_fora['Tamanho'] > 1000].index)

base_fora.loc[base_fora['Condominio'] > 10000]

#Excluir dados cujo condomínio é superior a 10000
base_fora = base_fora.drop(base_fora[base_fora['Condominio'] > 10000].index)

base_fora.loc[base_fora['Preço'] > 50000]

#Excluir dados cujo valor do preço é superior a 50000
base_fora = base_fora.drop(base_fora[base_fora['Preço'] > 50000].index)

grafico = px.scatter_matrix(base_fora, dimensions=['Tamanho', 'Condominio', 'Preço'])
grafico.show()

grafico = px.scatter_matrix(base_fora, dimensions=['Quartos', 'Banheiros', 'Estacionamento', 'Mobiliado', 'Preço'])
grafico.show()

base_fora.loc[base_fora['Quartos'] == 13]

base_fora.loc[base_fora['Quartos'] == 10]

#Excluir dados que possuem o número de quartos maiores ou iguais a 10
base_fora = base_fora.drop(base_fora[base_fora['Quartos'] == 13].index)
base_fora = base_fora.drop(base_fora[base_fora['Quartos'] == 10].index)

base_fora.loc[base_fora['Banheiros'] == 10]

#Excluir dados que possuem o número de banheiros iguais a 10.
base_fora = base_fora.drop(base_fora[base_fora['Banheiros'] == 10].index)

base_fora.loc[base_fora['Estacionamento'] == 10]

#Excluir dados que possuem o número de estacionamentos iguais a 10.
base_fora = base_fora.drop(base_fora[base_fora['Estacionamento'] == 10].index)

base_fora

"""#Juntando as duas base de dados"""

base_total = pd.concat([base_sp, base_fora])

base_total

"""##Análise/exploração dos dados"""

#Analise estatitica do df.
base_total.describe()

#Histograma das variáveis
base_total.hist(figsize=(13, 10))
plt.show()

#Correlação entre as variáveis
plt.figure(figsize=(13,10))
sns.heatmap(base_total.corr(),annot=True)
plt.title("Mapa correlação")
plt.show()

#Visualização dos dados
grafico = px.scatter_matrix(base_total, dimensions=['Tamanho', 'Condominio', 'Preço'])
grafico.show()

plt.scatter(base_total['Condominio'], base_total['Preço'])
plt.xlabel("Condomínio")
plt.ylabel("Preço")
plt.show()

plt.scatter(base_total['Tamanho'], base_total['Preço'], color = 'r')
plt.xlabel("Tamanho")
plt.ylabel("Preço")
plt.show()

"""##Divisão entre previsores e classe"""

#Previsores
X_total = base_total.iloc[:, 0:6].values

X_total

type(X_total)

#Classe
y_total = base_total.iloc[:,6].values

y_total

type(y_total)

"""##Divisão de bases de treinamento e teste"""

from sklearn.model_selection import train_test_split

X_total_treinamento, X_total_teste, y_total_treinamento, y_total_teste = train_test_split(X_total, y_total, test_size = 0.25, random_state = 42)

#Tamanho de cada vetor
X_total_treinamento.shape, y_total_treinamento.shape, X_total_teste.shape, y_total_teste.shape

"""##Regressão linear multipla"""

from sklearn.linear_model import LinearRegression
regressor_total = LinearRegression()
regressor_total.fit(X_total_treinamento, y_total_treinamento)

#score base de treinamento
regressor_total.score(X_total_treinamento, y_total_treinamento)

#score base de teste
regressor_total.score(X_total_teste, y_total_teste)

#coeficiente linear
regressor_total.intercept_

#todos os coeficientes 
regressor_total.coef_

previsoes = regressor_total.predict(X_total_teste)
previsoes

y_total_teste

#importanto a função erro médio absoluto
from sklearn.metrics import mean_absolute_error
mean_absolute_error(y_total_teste, previsoes)

"""##SVM"""

#Escalonamento de valores
from sklearn.preprocessing import StandardScaler
scaler_x_total = StandardScaler()
X_total_treinamento_scaled = scaler_x_total.fit_transform(X_total_treinamento)
scaler_y_total = StandardScaler()
y_total_treinamento_scaled = scaler_y_total.fit_transform(y_total_treinamento.reshape(-1,1))

X_total_teste_scaled = scaler_x_total.transform(X_total_teste)
y_total_teste_scaled = scaler_y_total.transform(y_total_teste.reshape(-1,1))

from sklearn.svm import SVR

regressor_svr_total = SVR(kernel='rbf')
regressor_svr_total.fit(X_total_treinamento_scaled, y_total_treinamento_scaled.ravel())

regressor_svr_total.score(X_total_treinamento_scaled, y_total_treinamento_scaled)

regressor_svr_total.score(X_total_teste_scaled, y_total_teste_scaled)

previsoes = regressor_svr_total.predict(X_total_teste_scaled)
previsoes

y_total_teste_inverse = scaler_y_total.inverse_transform(y_total_teste_scaled)
previsoes_inverse = scaler_y_total.inverse_transform(previsoes.reshape(-1,1))

from sklearn.metrics import mean_absolute_error
mean_absolute_error(y_total_teste_inverse, previsoes_inverse)

"""##Redes neurais"""

from sklearn.neural_network import MLPRegressor

# 16 -> 9 -> 9 -> 1
regressor_rna_total = MLPRegressor(max_iter=1000, hidden_layer_sizes=(9,9))
regressor_rna_total.fit(X_total_treinamento_scaled, y_total_treinamento_scaled.ravel())

regressor_rna_total.score(X_total_treinamento_scaled, y_total_treinamento_scaled)

regressor_rna_total.score(X_total_teste_scaled, y_total_teste_scaled)

previsoes = regressor_rna_total.predict(X_total_teste_scaled)
previsoes

y_total_teste_inverse = scaler_y_total.inverse_transform(y_total_teste_scaled)
previsoes_inverse = scaler_y_total.inverse_transform(previsoes.reshape(-1,1))

from sklearn.metrics import mean_absolute_error
mean_absolute_error(y_total_teste_inverse, previsoes_inverse)

"""##RGB"""

from sklearn.ensemble import GradientBoostingRegressor

regressorgb =  GradientBoostingRegressor()
regressorgb.fit(X_total_treinamento,y_total_treinamento)

regressorgb.score(X_total_treinamento, y_total_treinamento)

regressorgb.score(X_total_teste, y_total_teste)

previsoes = regressorgb.predict(X_total_teste)
previsoes

from sklearn.metrics import mean_absolute_error
mean_absolute_error(y_total_teste, previsoes)

#plotando o valor das previsoes e y_total
plt.figure(figsize=(10,10))
plt.scatter(y_total_teste, previsoes, c='crimson')
p1 = max(max(previsoes), max(y_total_teste))
p2 = min(min(previsoes), min(y_total_teste))
plt.plot([p1, p2], [p1, p2], 'b-')
plt.xlabel('y_total_teste', fontsize=15)
plt.ylabel('previsoes', fontsize=15)
plt.axis('equal')
plt.show()

len(previsoes)

count = np.arange(1,4472)

plt.figure(figsize=(12,5))
plt.plot(count, y_total_teste, color ="red")
plt.plot(count, previsoes)
plt.title("Comparação entre previsões e os valores de teste")
plt.gca().legend(('Teste','Previsões'))

plt.show()

"""## Cross validation"""

def ApplyesKFold(x, y):
  # Modelos utilizados.
  from sklearn.linear_model import LinearRegression
  from sklearn.svm import SVR
  from sklearn.neural_network import MLPRegressor
  from sklearn.ensemble import GradientBoostingRegressor

  # Cross-Validation Modelos.
  from sklearn.model_selection import cross_val_score
  from sklearn.model_selection import KFold

  # KFold parâmetros.
  kfold  = KFold(n_splits=15, shuffle=True) #n_splits = (subdivisões) shuffle=True, Shuffle (aleatoriedade dos dados).

  # Eixos
  X_total = x
  y_total = y
  
  #Escalonamento de valores
  from sklearn.preprocessing import StandardScaler
  scaler_X_total = StandardScaler()
  X_total_scaled = scaler_X_total.fit_transform(X_total)
  scaler_y_total = StandardScaler()
  y_total_scaled = scaler_y_total.fit_transform(y_total.reshape(-1,1))



  # Instancia dos modelos.
  regressor_total1 = LinearRegression()
  regressor_svr_total1 = SVR(kernel='rbf')
  regressor_rna_total1 = MLPRegressor(max_iter=1000, hidden_layer_sizes=(9,9))
  regressorgb_total1 =  GradientBoostingRegressor()


  # Aplicando K-fold nos modelos.
  linearRegression_result = cross_val_score(regressor_total1, X_total, y_total, cv = kfold)
  svr_result = cross_val_score(regressor_svr_total1, X_total_scaled, y_total_scaled.ravel(), cv = kfold)
  rna_result = cross_val_score(regressor_rna_total1, X_total_scaled, y_total_scaled.ravel(), cv = kfold)
  regressorgb_result = cross_val_score(regressorgb_total1, X_total, y_total, cv = kfold)


  # Criando dicionário para guardar as médias.
  dic_models = {
    "LinearRegression": linearRegression_result.mean(),
    "svr": svr_result.mean(),
    "rna": rna_result.mean(),
    "rgb": regressorgb_result.mean()
  }
  # Selecionando o melhor modelo.
  bestModel = max(dic_models, key=dic_models.get)

  print("Linear Regression Média (R^2): {0}\nsvr Média (R^2): {1}\nrna Média (R^2): {2}\nrgb Média (R^2): {3}"
  .format(linearRegression_result.mean(), svr_result.mean(), rna_result.mean(),regressorgb_result.mean()))
  print("O melhor modelo é: {0} com valor: {1}".format(bestModel, dic_models[bestModel]))

ApplyesKFold(X_total, y_total)